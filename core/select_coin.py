"""
é‚¢ä¸è¡Œï½œç­–ç•¥åˆ†äº«ä¼š
é€‰å¸ç­–ç•¥æ¡†æ¶ğ“Ÿğ“»ğ“¸

ç‰ˆæƒæ‰€æœ‰ Â©ï¸ é‚¢ä¸è¡Œ
å¾®ä¿¡: xbx1717

æœ¬ä»£ç ä»…ä¾›ä¸ªäººå­¦ä¹ ä½¿ç”¨ï¼Œæœªç»æˆæƒä¸å¾—å¤åˆ¶ã€ä¿®æ”¹æˆ–ç”¨äºå•†ä¸šç”¨é€”ã€‚

Author: é‚¢ä¸è¡Œ
"""
import gc
import os
import time
import warnings
from concurrent.futures import ProcessPoolExecutor, as_completed
from pathlib import Path
from typing import List

import numpy as np
import pandas as pd
from tqdm import tqdm

from config import job_num, factor_col_limit
from core.model.backtest_config import BacktestConfig, StrategyConfig
from core.utils.factor_hub import FactorHub
from core.utils.log_kit import logger
from core.utils.path_kit import get_file_path

warnings.filterwarnings('ignore')
# pandasç›¸å…³çš„æ˜¾ç¤ºè®¾ç½®ï¼ŒåŸºç¡€è¯¾ç¨‹éƒ½æœ‰ä»‹ç»
pd.set_option('display.max_rows', 1000)
pd.set_option('expand_frame_repr', False)  # å½“åˆ—å¤ªå¤šæ—¶ä¸æ¢è¡Œ
pd.set_option('display.unicode.ambiguous_as_wide', True)  # è®¾ç½®å‘½ä»¤è¡Œè¾“å‡ºæ—¶çš„åˆ—å¯¹é½åŠŸèƒ½
pd.set_option('display.unicode.east_asian_width', True)

# è®¡ç®—å®Œå› å­ä¹‹åï¼Œä¿ç•™çš„å­—æ®µ
KLINE_COLS = ['candle_begin_time', 'symbol', 'is_spot', 'close', 'next_close', 'symbol_spot', 'symbol_swap', 'æ˜¯å¦äº¤æ˜“']
# è®¡ç®—å®Œé€‰å¸ä¹‹åï¼Œä¿ç•™çš„å­—æ®µ
SELECT_RES_COLS = [*KLINE_COLS, 'strategy', 'cap_weight', 'æ–¹å‘', 'offset', 'target_alloc_ratio']
# å®Œæ•´klineæ•°æ®ä¿å­˜çš„è·¯å¾„
ALL_KLINE_PATH_TUPLE = ('data', 'cache', 'all_factors_kline.pkl')


# ======================================================================================
# å› å­è®¡ç®—ç›¸å…³å‡½æ•°
# - calc_factors_by_symbol: è®¡ç®—å•ä¸ªå¸ç§çš„å› å­æ± 
# - calc_factors: è®¡ç®—å› å­æ± 
# ======================================================================================

def trans_period_for_day(df, date_col='candle_begin_time', factor_dict=None):
    """
    å°†æ•°æ®å‘¨æœŸè½¬æ¢ä¸ºæŒ‡å®šçš„1Då‘¨æœŸ
    :param df: åŸå§‹æ•°æ®
    :param date_col: æ—¥æœŸåˆ—
    :param factor_dict: è½¬æ¢è§„åˆ™
    :return:
    """
    df.set_index(date_col, inplace=True)
    # å¿…å¤‡å­—æ®µ
    agg_dict = {
        'symbol': 'first',
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum',
        'quote_volume': 'sum',
        'trade_num': 'sum',
        'taker_buy_base_asset_volume': 'sum',
        'taker_buy_quote_asset_volume': 'sum',
        'is_spot': 'last',
        # 'has_swap': 'last',
        'symbol_swap': 'last',
        'symbol_spot': 'last',
        'funding_fee': 'sum',
        'next_avg_price': 'last',
        'æ˜¯å¦äº¤æ˜“': 'last',
    }

    if factor_dict:
        agg_dict = dict(agg_dict, **factor_dict)
    df = df.resample('1D').agg(agg_dict)
    df.reset_index(inplace=True)

    return df


# region å› å­è®¡ç®—ç›¸å…³å‡½æ•°
def calc_factors_by_candle(candle_df, conf: BacktestConfig, factor_col_name_list) -> pd.DataFrame:
    """
    é’ˆå¯¹å•ä¸€æ¯”å¯¹ï¼Œè®¡ç®—æ‰€æœ‰å› å­çš„æ•°å€¼
    :param candle_df: ä¸€ä¸ªå¸ç§çš„kçº¿æ•°æ® dataframe
    :param conf: å›æµ‹é…ç½®
    :param factor_col_name_list: éœ€è¦è®¡ç®—çš„å› å­åˆ—
    :return: åŒ…å«æ‰€æœ‰å› å­çš„ dataframe(ç›®å‰æ˜¯åŒ…å«kçº¿æ•°æ®çš„ï¼‰
    """
    # éå†æ¯ä¸ªå› å­ï¼Œè®¡ç®—æ¯ä¸ªå› å­çš„æ•°æ®
    factor_series_dict = {}
    for factor_name, param_list in conf.factor_params_dict.items():
        factor = FactorHub.get_by_name(factor_name)  # è·å–å› å­ä¿¡æ¯

        # ç­›é€‰ä¸€ä¸‹éœ€è¦è®¡ç®—çš„å› å­
        factor_param_list = []
        for param in param_list:
            factor_col_name = f'{factor_name}_{param}'
            if factor_col_name in factor_col_name_list:
                factor_param_list.append(param)
        if len(factor_param_list) == 0:
            continue  # å½“è¯¥å› å­ä¸éœ€è¦è®¡ç®—çš„æ—¶å€™ç›´æ¥è¿”å›

        # å¦‚æœå­˜åœ¨å¤–éƒ¨æ•°æ®ï¼Œåˆ™ä½¿ç”¨ data_bridge ä¸­çš„åŠ è½½å‡½æ•° load æ•°æ®
        if hasattr(factor, 'extra_data_dict') and factor.extra_data_dict:
            from core.utils.functions import merge_data
            for data_name in factor.extra_data_dict.keys():
                extra_data_dict = merge_data(candle_df, data_name, factor.extra_data_dict[data_name])
                for extra_data_name, extra_data_series in extra_data_dict.items():
                    candle_df[extra_data_name] = extra_data_series.values

        # æ ¹æ®å› å­å†…éƒ¨çš„å‡½æ•°ï¼Œæ¥åˆ¤æ–­æ˜¯å¦è¿›è¡ŒåŠ é€Ÿæ“ä½œ
        if hasattr(factor, 'signal_multi_params'):  # å¦‚æœå­˜åœ¨ signal_multi_params ï¼Œä½¿ç”¨æœ€æ–°çš„å› å­åŠ é€Ÿå†™æ³•
            result_dict = factor.signal_multi_params(candle_df, factor_param_list)
            for param, factor_series in result_dict.items():
                factor_series_dict[f'{factor_name}_{param}'] = factor_series.values

        else:  # å¦‚æœå­˜åœ¨ signalï¼Œä½¿ç”¨ä¹‹å‰çš„è€å› å­å†™æ³•
            legacy_candle_df = candle_df.copy()  # å¦‚æœæ˜¯è€çš„å› å­è®¡ç®—é€»è¾‘ï¼Œå•ç‹¬æ‹¿å‡ºæ¥ä¸€ä»½æ•°æ®
            for param in factor_param_list:
                factor_col_name = f'{factor_name}_{param}'
                legacy_candle_df = factor.signal(legacy_candle_df, param, factor_col_name)
                factor_series_dict[factor_col_name] = legacy_candle_df[factor_col_name].values

    # å°†ç»“æœ DataFrame ä¸åŸå§‹ DataFrame åˆå¹¶
    kline_with_factor_dict = {
        'candle_begin_time': candle_df['candle_begin_time'].values,
        'symbol': candle_df['symbol'].values,
        'is_spot': candle_df['is_spot'].values,
        'close': candle_df['close'].values,
        # 'has_swap': candle_df['has_swap'],
        # 'next_avg_price': candle_df['next_avg_price'].values,
        'next_close': candle_df['close'].shift(-1).values,  # åé¢å‘¨æœŸæ’é™¤éœ€è¦ç”¨
        # 'next_funding_fee': candle_df['funding_fee'].shift(-1).values,
        'symbol_spot': candle_df['symbol_spot'].astype(str).values,
        'symbol_swap': candle_df['symbol_swap'].astype(str).values,
        **factor_series_dict,
        'æ˜¯å¦äº¤æ˜“': candle_df['æ˜¯å¦äº¤æ˜“'].values,
    }

    kline_with_factor_df = pd.DataFrame(kline_with_factor_dict, copy=False)
    kline_with_factor_df.sort_values(by='candle_begin_time', inplace=True)

    # æŠ›å¼ƒä¸€å¼€å§‹çš„ä¸€æ®µkçº¿ï¼Œä¿ç•™åé¢çš„æ•°æ®
    first_candle_time = candle_df.iloc[0]['first_candle_time'] + pd.to_timedelta(f'{conf.min_kline_num}h')

    # è°ƒæ•´ symbol_spot å’Œ symbol_swap
    # for col in ['symbol_spot', 'symbol_swap']:
    #     symbol_start_time = candle_df[
    #         (candle_df[col] != '') & (candle_df[col].shift(1) == '') & (~candle_df[col].shift(1).isna())
    #         ]['candle_begin_time']
    #     if not symbol_start_time.empty:
    #         condition = pd.Series(False, index=kline_with_factor_df.index)
    #         for symbol_time in symbol_start_time:
    #             _cond1 = kline_with_factor_df['candle_begin_time'] > symbol_time
    #             _cond2 = kline_with_factor_df['candle_begin_time'] <= symbol_time + pd.to_timedelta(
    #                 f'{conf.min_kline_num}h')
    #             condition |= (_cond1 & _cond2)
    #         kline_with_factor_df.loc[condition, col] = ''
    #     kline_with_factor_df[col] = kline_with_factor_df[col].astype('category')

    # éœ€è¦å¯¹æ•°æ®è¿›è¡Œè£åˆ‡
    kline_with_factor_df = kline_with_factor_df[kline_with_factor_df['candle_begin_time'] >= first_candle_time]

    # ä¸‹æ¶å¸/æ‹†åˆ†å¸ï¼Œå»æ‰æœ€åä¸€ä¸ªå‘¨æœŸä¸å…¨çš„æ•°æ®
    if kline_with_factor_df['candle_begin_time'].max() < pd.to_datetime(conf.end_date):
        _temp_time = kline_with_factor_df['candle_begin_time'] + pd.Timedelta(conf.max_hold_period)
        _del_time = kline_with_factor_df[kline_with_factor_df.loc[_temp_time.index, 'next_close'].isna()][
            'candle_begin_time']
        kline_with_factor_df = kline_with_factor_df[
            kline_with_factor_df['candle_begin_time'] <= _del_time.min() - pd.Timedelta(conf.max_hold_period)]

    # åªä¿ç•™æœ€è¿‘çš„æ•°æ®
    kline_with_factor_df = kline_with_factor_df[
        (kline_with_factor_df['candle_begin_time'] >= pd.to_datetime(conf.start_date)) &
        (kline_with_factor_df['candle_begin_time'] < pd.to_datetime(conf.end_date))]

    # åªä¿ç•™éœ€è¦çš„å­—æ®µ
    return kline_with_factor_df


def process_candle_df(candle_df: pd.DataFrame, conf: BacktestConfig, factor_col_name_list: List[str], idx: int):
    """
    # é’ˆå¯¹æ¯ä¸€ä¸ªå¸ç§çš„kçº¿æ•°æ®ï¼ŒæŒ‰ç…§ç­–ç•¥å¾ªç¯è®¡ç®—å› å­ä¿¡æ¯
    :param candle_df: å•ä¸ªå¸ç§çš„æ•°æ®
    :param conf: backtest config
    :param factor_col_name_list:    å› å­åˆ—è¡¨ï¼Œå¯ä»¥ç”¨äºåŠ¨æ€åˆ¤æ–­å½“å‰éœ€è¦è®¡ç®—çš„å› å­åˆ—ã€‚
                                    å½“ factor_col_name_list â‰  conf.factor_col_name_list æ—¶ï¼Œè¯´æ˜éœ€è¦èŠ‚çœä¸€ç‚¹å†…å­˜
    :param idx: ç´¢å¼•
    :return: å¸¦æœ‰å› å­æ•°å€¼çš„æ•°æ®
    """
    # ==== æ•°æ®é¢„å¤„ç† ====
    factor_dict = {'first_candle_time': 'first', 'last_candle_time': 'last'}
    for strategy in conf.strategy_list:
        symbol = candle_df['symbol'].iloc[-1]
        candle_df, _factor_dict, _ = strategy.after_merge_index(candle_df, symbol, factor_dict, {})
        factor_dict.update(_factor_dict)

    # è®¡ç®—å¹³å‡å¼€ç›˜ä»·æ ¼
    candle_df['next_avg_price'] = candle_df[conf.avg_price_col].shift(-1)  # ç”¨äºåé¢è®¡ç®—å½“å‘¨æœŸæ¶¨è·Œå¹…

    # è½¬æ¢æˆæ—¥çº¿æ•°æ®  è·Ÿå›æµ‹ä¿æŒä¸€è‡´
    if conf.is_day_period:
        candle_df = trans_period_for_day(candle_df, factor_dict=factor_dict)

    # ==== è®¡ç®—å› å­ ====
    # æ¸…ç†æ‰å¤´éƒ¨å‚ä¸æ—¥çº¿è½¬æ¢çš„å¡«å……æ•°æ®
    candle_df.dropna(subset=['symbol'], inplace=True)
    candle_df.reset_index(drop=True, inplace=True)
    # é’ˆå¯¹å•ä¸ªå¸ç§çš„Kçº¿æ•°æ®è®¡ç®—
    # è¿”å›å¸¦æœ‰å› å­æ•°å€¼çš„Kçº¿æ•°æ®
    factor_df = calc_factors_by_candle(candle_df, conf, factor_col_name_list)

    return idx, factor_df


def calc_factors(conf: BacktestConfig):
    """
    é€‰å¸å› å­è®¡ç®—ï¼Œè€ƒè™‘åˆ°å¤§å› å­å›æµ‹çš„åœºæ™¯ï¼Œæˆ‘ä»¬å¼•å…¥chunkçš„æ¦‚å¿µï¼Œä¼šæŠŠæ‰€æœ‰factoråˆ‡æˆå¤šåˆ†ï¼Œç„¶ååˆ†åˆ«è®¡ç®—
    :param conf:       è´¦æˆ·ä¿¡æ¯
    :return:
    """
    # ====================================================================================================
    # 1. ** kçº¿æ•°æ®æ•´ç†åŠå‚æ•°å‡†å¤‡ **
    # - is_use_spot: Trueçš„æ—¶å€™ï¼Œä½¿ç”¨ç°è´§æ•°æ®å’Œåˆçº¦æ•°æ®;
    # - Falseçš„æ—¶å€™ï¼Œåªä½¿ç”¨åˆçº¦æ•°æ®ã€‚æ‰€ä»¥è¿™ä¸ªæƒ…å†µæ›´ç®€å•
    # ====================================================================================================
    # hold_periodçš„ä½œç”¨æ˜¯è®¡ç®—å®Œå› å­ä¹‹åï¼Œ
    # è·å–æœ€è¿‘ hold_period ä¸ªå°æ—¶å†…çš„æ•°æ®ä¿¡æ¯ï¼Œ
    # åŒæ—¶ç”¨äºoffsetå­—æ®µè®¡ç®—ä½¿ç”¨
    # ====================================================================================================
    # 2. ** å› å­è®¡ç®— **
    # éå†æ¯ä¸ªå¸ç§ï¼Œè®¡ç®—ç›¸å…³å› å­æ•°æ®
    # ====================================================================================================
    candle_df_list = pd.read_pickle(get_file_path('data', 'cache', 'all_candle_df_list.pkl'))
    factor_col_count = len(conf.factor_col_name_list)
    shards = range(0, factor_col_count, factor_col_limit)

    logger.debug(f'''* æ€»å…±è®¡ç®—å› å­ä¸ªæ•°ï¼š{factor_col_count} ä¸ª
* å•æ¬¡è®¡ç®—å› å­ä¸ªæ•°ï¼š{factor_col_limit} ä¸ªï¼Œ(éœ€åˆ†æˆ{len(shards)}ç»„è®¡ç®—)
* éœ€è¦è®¡ç®—å¸ç§æ•°é‡ï¼š{len(candle_df_list)} ä¸ª''')

    # æ¸…ç† cache çš„ç¼“å­˜
    all_kline_pkl = get_file_path(*ALL_KLINE_PATH_TUPLE, as_path_type=True)
    all_kline_pkl.unlink(missing_ok=True)

    for shard_index in shards:
        logger.debug(f'ğŸš€ å› å­åˆ†ç‰‡è®¡ç®—ä¸­ï¼Œè¿›åº¦ï¼š{int(shard_index / factor_col_limit) + 1}/{len(shards)}')
        factor_col_name_list = conf.factor_col_name_list[shard_index:shard_index + factor_col_limit]

        all_factor_df_list = [pd.DataFrame()] * len(candle_df_list)
        with ProcessPoolExecutor(max_workers=job_num) as executor:
            futures = [executor.submit(
                process_candle_df, candle_df.copy(), conf, factor_col_name_list, candle_idx
            ) for candle_idx, candle_df in enumerate(candle_df_list)]

            for future in tqdm(as_completed(futures), total=len(candle_df_list), desc='ğŸ§® å› å­è®¡ç®—'):
                idx, factor_df = future.result()
                all_factor_df_list[idx] = factor_df

        # ====================================================================================================
        # 3. ** åˆå¹¶å› å­ç»“æœ **
        # åˆå¹¶å¹¶æ•´ç†æ‰€æœ‰Kçº¿ï¼Œåˆ°è¿™é‡Œå› å­è®¡ç®—å®Œæˆ
        # ====================================================================================================
        all_factors_df = pd.concat(all_factor_df_list, ignore_index=True)
        all_factors_df['symbol'] = pd.Categorical(all_factors_df['symbol'])

        del all_factor_df_list

        # ====================================================================================================
        # 4. ** å› å­ç»“æœåˆ†ç‰‡å­˜å‚¨ **
        # åˆ†ç‰‡å­˜å‚¨è®¡ç®—ç»“æœï¼ŒèŠ‚çœå†…å­˜å ç”¨ï¼Œæé«˜é€‰å¸æ•ˆç‡
        # - å°†åˆå¹¶å¥½çš„dfï¼Œåˆ†æˆ2ä¸ªéƒ¨åˆ†ï¼škçº¿å’Œå› å­åˆ—
        # - kçº¿æ•°æ®å­˜å‚¨ä¸ºä¸€ä¸ªpklï¼Œæ¯ä¸€åˆ—å› å­å­˜å‚¨ä¸ºä¸€ä¸ªpklï¼Œåœ¨é€‰å¸æ—¶å€™æŒ‰éœ€è¯»å…¥åˆå¹¶æˆdf
        # ====================================================================================================
        logger.debug('ğŸ’¾ åˆ†ç‰‡å­˜å‚¨å› å­ç»“æœ...')

        # é€‰å¸éœ€è¦çš„kçº¿
        if not all_kline_pkl.exists():
            all_kline_df = all_factors_df[KLINE_COLS].sort_values(by=['candle_begin_time', 'symbol', 'is_spot'])
            all_kline_df.to_pickle(all_kline_pkl)

        # é’ˆå¯¹æ¯ä¸€ä¸ªå› å­è¿›è¡Œå­˜å‚¨
        for factor_col_name in factor_col_name_list:
            factor_pkl = get_file_path('data', 'cache', f'factor_{factor_col_name}.pkl', as_path_type=True)
            factor_pkl.unlink(missing_ok=True)  # åŠ¨æ€æ¸…ç†æ‰cacheçš„ç¼“å­˜
            all_factors_df[factor_col_name].to_pickle(factor_pkl)

        del all_factors_df

        gc.collect()


# endregion

# ======================================================================================
# é€‰å¸ç›¸å…³å‡½æ•°
# - calc_select_factor_rank: è®¡ç®—å› å­æ’åº
# - select_long_and_short_coin: é€‰åšå¤šå’Œåšç©ºçš„å¸ç§
# - select_coins_by_strategy: æ ¹æ®ç­–ç•¥é€‰å¸
# - select_coins: é€‰å¸ï¼Œå¾ªç¯ç­–ç•¥è°ƒç”¨ `select_coins_by_strategy`
# ======================================================================================
# region é€‰å¸ç›¸å…³å‡½æ•°
def calc_select_factor_rank(df, factor_column='å› å­', ascending=True):
    """
    è®¡ç®—å› å­æ’å
    :param df:              åŸæ•°æ®
    :param factor_column:   éœ€è¦è®¡ç®—æ’åçš„å› å­åç§°
    :param ascending:       è®¡ç®—æ’åé¡ºåºï¼ŒTrueï¼šä»å°åˆ°å¤§æ’åºï¼›Falseï¼šä»å¤§åˆ°å°æ’åº
    :return:                è®¡ç®—æ’ååçš„æ•°æ®æ¡†
    """
    # è®¡ç®—å› å­çš„åˆ†ç»„æ’å
    df['rank'] = df.groupby('candle_begin_time')[factor_column].rank(method='min', ascending=ascending)
    df['rank_max'] = df.groupby('candle_begin_time')['rank'].transform('max')
    # æ ¹æ®æ—¶é—´å’Œå› å­æ’åæ’åº
    df.sort_values(by=['candle_begin_time', 'rank'], inplace=True)
    # é‡æ–°è®¡ç®—ä¸€ä¸‹æ€»å¸æ•°
    df['æ€»å¸æ•°'] = df.groupby('candle_begin_time')['symbol'].transform('size')
    return df


def select_long_and_short_coin(strategy: StrategyConfig, long_df: pd.DataFrame, short_df: pd.DataFrame):
    """
    é€‰å¸ï¼Œæ·»åŠ å¤šç©ºèµ„é‡‘æƒé‡åï¼Œå¯¹äºæ— æƒé‡çš„æƒ…å†µï¼Œå‡å°‘é€‰å¸æ¬¡æ•°

    :param strategy:                ç­–ç•¥ï¼ŒåŒ…å«ï¼šå¤šå¤´é€‰å¸æ•°é‡ï¼Œç©ºå¤´é€‰å¸æ•°é‡ï¼Œåšå¤šå› å­åç§°ï¼Œåšç©ºå› å­åç§°ï¼Œå¤šå¤´èµ„é‡‘æƒé‡ï¼Œç©ºå¤´èµ„é‡‘æƒé‡
    :param long_df:                 å¤šå¤´é€‰å¸çš„df
    :param short_df:                ç©ºå¤´é€‰å¸çš„df
    :return:
    """
    """
    # åšå¤šé€‰å¸
    """
    if strategy.long_cap_weight > 0:
        long_df = calc_select_factor_rank(long_df, factor_column=strategy.long_factor, ascending=True)

        long_df = strategy.select_by_coin_num(long_df, strategy.long_select_coin_num)

        long_df['æ–¹å‘'] = 1
        long_df['target_alloc_ratio'] = 1 / long_df.groupby('candle_begin_time')['symbol'].transform('size')
    else:
        long_df = pd.DataFrame()

    """
    # åšç©ºé€‰å¸
    """
    if strategy.short_cap_weight > 0:
        short_df = calc_select_factor_rank(short_df, factor_column=strategy.short_factor, ascending=False)

        if strategy.short_select_coin_num == 'long_nums':  # å¦‚æœå‚æ•°æ˜¯long_numsï¼Œåˆ™ç©ºå¤´ä¸å¤šå¤´çš„é€‰å¸æ•°é‡ä¿æŒä¸€è‡´
            # è·å–åˆ°å¤šå¤´çš„é€‰å¸æ•°é‡å¹¶æ•´ç†æ•°æ®
            long_select_num = long_df.groupby('candle_begin_time')['symbol'].size().to_frame()
            long_select_num = long_select_num.rename(columns={'symbol': 'å¤šå¤´æ•°é‡'}).reset_index()
            # å°†å¤šå¤´é€‰å¸æ•°é‡æ•´ç†åˆ°short_df
            short_df = short_df.merge(long_select_num, on='candle_begin_time', how='left')
            # ä½¿ç”¨å¤šå¤´æ•°é‡å¯¹ç©ºå¤´æ•°æ®è¿›è¡Œé€‰å¸
            short_df = short_df[short_df['rank'] <= short_df['å¤šå¤´æ•°é‡']]
            del short_df['å¤šå¤´æ•°é‡']
        else:
            short_df = strategy.select_by_coin_num(short_df, strategy.short_select_coin_num)

        short_df['æ–¹å‘'] = -1
        short_df['target_alloc_ratio'] = 1 / short_df.groupby('candle_begin_time')['symbol'].transform('size')
    else:
        short_df = pd.DataFrame()

    # ===æ•´ç†æ•°æ®
    df = pd.concat([long_df, short_df], ignore_index=True)  # å°†åšå¤šå’Œåšç©ºçš„å¸ç§æ•°æ®åˆå¹¶
    df.sort_values(by=['candle_begin_time', 'æ–¹å‘'], ascending=[True, False], inplace=True)
    df.reset_index(drop=True, inplace=True)

    del df['æ€»å¸æ•°'], df['rank_max']

    return df


def select_coins_by_strategy(factor_df, stg_conf: StrategyConfig):
    """
    é’ˆå¯¹æ¯ä¸€ä¸ªç­–ç•¥ï¼Œè¿›è¡Œé€‰å¸ï¼Œå…·ä½“åˆ†ä¸ºä»¥ä¸‹4æ­¥ï¼š
    - 4.1 æ•°æ®æ¸…æ´—
    - 4.2 è®¡ç®—ç›®æ ‡é€‰å¸å› å­
    - 4.3 å‰ç½®è¿‡æ»¤ç­›é€‰
    - 4.4 æ ¹æ®é€‰å¸å› å­è¿›è¡Œé€‰å¸
    :param stg_conf: ç­–ç•¥é…ç½®
    :param factor_df: æ‰€æœ‰å¸ç§Kçº¿æ•°æ®ï¼Œä»…åŒ…å«éƒ¨åˆ†è¡Œæƒ…æ•°æ®å’Œé€‰å¸éœ€è¦çš„å› å­åˆ—
    :return: é€‰å¸æ•°æ®
    """

    """
    4.1 æ•°æ®é¢„å¤„ç†
    å¯ä»¥é¢„ç•™ä¸€äº›ç©ºé—´ç»™æ•°æ®æ•´ç†ï¼Œæ¯”å¦‚ç¼ºå¤±æ•°æ®çš„å¤„ç†
    """
    pass

    """
    4.2 è®¡ç®—ç›®æ ‡é€‰å¸å› å­
    """
    s = time.time()
    # ç¼“å­˜è®¡ç®—å‰çš„åˆ—å
    prev_cols = factor_df.columns
    # è®¡ç®—å› å­
    result_df = stg_conf.calc_select_factor(factor_df)
    # åˆå¹¶æ–°çš„å› å­
    factor_df = factor_df[prev_cols].join(result_df[list(set(result_df.columns) - set(prev_cols))])
    logger.debug(f'[{stg_conf.name}] é€‰å¸å› å­è®¡ç®—è€—æ—¶ï¼š{time.time() - s:.2f}s')

    """
    4.3 å‰ç½®è¿‡æ»¤ç­›é€‰
    """
    s = time.time()
    long_df, short_df = stg_conf.filter_before_select(factor_df)
    if stg_conf.is_use_spot:  # ä½¿ç”¨ç°è´§æ•°æ®ï¼Œåˆ™åœ¨ç°è´§ä¸­è¿›è¡Œè¿‡æ»¤ï¼Œå¹¶é€‰å¸
        short_df = short_df[short_df['symbol_swap'] != '']  # ä¿ç•™æœ‰åˆçº¦çš„ç°è´§
    logger.debug(f'[{stg_conf.name}] å‰ç½®è¿‡æ»¤è€—æ—¶ï¼š{time.time() - s:.2f}s')

    """
    4.4 æ ¹æ®é€‰å¸å› å­è¿›è¡Œé€‰å¸
    """
    s = time.time()
    # å¤šå¤´é€‰å¸æ•°æ®ã€ç©ºå¤´é€‰å¸æ•°æ®ã€ç­–ç•¥é…ç½®
    factor_df = select_long_and_short_coin(stg_conf, long_df, short_df)
    logger.debug(f'[{stg_conf.name}] å¤šç©ºé€‰å¸è€—æ—¶ï¼š{time.time() - s:.2f}s')

    """
    4.5 åç½®è¿‡æ»¤ç­›é€‰
    """
    factor_df = stg_conf.filter_after_select(factor_df)
    logger.debug(f'[{stg_conf.name}] åç½®è¿‡æ»¤è€—æ—¶ï¼š{time.time() - s:.2f}s')

    """
    4.6 æ ¹æ®å¤šç©ºæ¯”è°ƒæ•´å¸ç§çš„æƒé‡
    """
    long_ratio = stg_conf.long_cap_weight / (stg_conf.long_cap_weight + stg_conf.short_cap_weight)
    factor_df.loc[factor_df['æ–¹å‘'] == 1, 'target_alloc_ratio'] = factor_df['target_alloc_ratio'] * long_ratio
    factor_df.loc[factor_df['æ–¹å‘'] == -1, 'target_alloc_ratio'] = factor_df['target_alloc_ratio'] * (1 - long_ratio)
    factor_df = factor_df[factor_df['target_alloc_ratio'].abs() > 1e-9]  # å»é™¤æƒé‡ä¸º0çš„æ•°æ®

    return factor_df[[*KLINE_COLS, 'æ–¹å‘', 'target_alloc_ratio']]


def process_strategy(stg_conf: StrategyConfig, result_folder: Path):
    s = time.time()
    strategy_name = stg_conf.name
    logger.debug(f'[{stg_conf.name}] å¼€å§‹é€‰å¸...')

    # å‡†å¤‡é€‰å¸ç”¨æ•°æ®
    factor_df = pd.read_pickle(get_file_path(*ALL_KLINE_PATH_TUPLE))
    for factor_col_name in stg_conf.factor_columns:
        factor_df[factor_col_name] = pd.read_pickle(
            get_file_path('data', 'cache', f'factor_{factor_col_name}.pkl'))
    factor_df = factor_df[factor_df['æ˜¯å¦äº¤æ˜“'] == 1]

    condition = (factor_df['is_spot'] == (1 if stg_conf.is_use_spot else 0))
    factor_df = factor_df.loc[condition, :].copy()
    factor_df.dropna(subset=stg_conf.factor_columns, inplace=True)
    factor_df.dropna(subset=['symbol'], how='any', inplace=True)

    factor_df.sort_values(by=['candle_begin_time', 'symbol'], inplace=True)
    factor_df.reset_index(drop=True, inplace=True)

    logger.debug(f'[{stg_conf.name}] é€‰å¸æ•°æ®å‡†å¤‡å®Œæˆï¼Œæ¶ˆè€—æ—¶é—´ï¼š{time.time() - s:.2f}s')

    result_df = select_coins_by_strategy(factor_df, stg_conf)
    # ç”¨äºç¼“å­˜é€‰å¸ç»“æœï¼Œå¦‚æœç»“æœä¸ºç©ºï¼Œä¹Ÿä¼šç”Ÿæˆå¯¹åº”çš„ï¼Œç©ºçš„pklæ–‡ä»¶
    stg_select_result = result_folder / f'{stg_conf.get_fullname(as_folder_name=True)}.pkl'

    if result_df.empty:
        pd.DataFrame(columns=SELECT_RES_COLS).to_pickle(stg_select_result)
        return

    del factor_df

    # ç­›é€‰åˆé€‚çš„offset
    cal_offset_base_seconds = 3600 * 24 if stg_conf.is_day_period else 3600
    reference_date = pd.to_datetime('2017-01-01')
    time_diff_seconds = (result_df['candle_begin_time'] - reference_date).dt.total_seconds()
    offset = (time_diff_seconds / cal_offset_base_seconds).mod(stg_conf.period_num).astype('int8')
    result_df['offset'] = ((offset + 1 + stg_conf.period_num) % stg_conf.period_num).astype('int8')
    result_df = result_df[result_df['offset'].isin(stg_conf.offset_list)]

    if result_df.empty:
        pd.DataFrame(columns=SELECT_RES_COLS).to_pickle(stg_select_result)
        return

    # æ·»åŠ å…¶ä»–çš„ç›¸å…³é€‰å¸ä¿¡æ¯
    select_result_dict = dict()
    for kline_col in KLINE_COLS:
        select_result_dict[kline_col] = result_df[kline_col].values

    select_result_dict['æ–¹å‘'] = result_df['æ–¹å‘'].astype('int8').values
    select_result_dict['offset'] = result_df['offset'].astype('int8').values
    select_result_dict['target_alloc_ratio'] = result_df['target_alloc_ratio'].values
    select_result_df = pd.DataFrame(select_result_dict, copy=False)
    del result_df

    select_result_df['strategy'] = strategy_name
    select_result_df['strategy'] = pd.Categorical(select_result_df['strategy'])

    # æ ¹æ®ç­–ç•¥èµ„é‡‘æƒé‡ï¼Œè°ƒæ•´ç›®æ ‡åˆ†é…æ¯”ä¾‹
    select_result_df['cap_weight'] = np.float64(stg_conf.cap_weight)
    select_result_df['target_alloc_ratio'] = np.float64(
        select_result_df['target_alloc_ratio']
        * select_result_df['cap_weight']
        / len(stg_conf.offset_list)
        * select_result_df['æ–¹å‘']
    )

    # ç¼“å­˜åˆ°æœ¬åœ°æ–‡ä»¶
    select_result_df[SELECT_RES_COLS].to_pickle(stg_select_result)

    logger.debug(f'[{strategy_name}] è€—æ—¶: {(time.time() - s):.2f}s')

    gc.collect()


# é€‰å¸æ•°æ®æ•´ç† & é€‰å¸
def select_coin_with_conf(conf: BacktestConfig, multi_process=True, silent=False):
    """
    ** ç­–ç•¥é€‰å¸ **
    - is_use_spot: Trueçš„æ—¶å€™ï¼Œä½¿ç”¨ç°è´§æ•°æ®å’Œåˆçº¦æ•°æ®;
    - Falseçš„æ—¶å€™ï¼Œåªä½¿ç”¨åˆçº¦æ•°æ®ã€‚æ‰€ä»¥è¿™ä¸ªæƒ…å†µæ›´ç®€å•

    :param conf: å›æµ‹é…ç½®
    :param multi_process: æ˜¯å¦å¯ç”¨å¤šè¿›ç¨‹
    :param silent: æ˜¯å¦é™é»˜
    :return:
    """
    if silent:
        import logging
        logger.setLevel(logging.WARNING)  # å¯ä»¥å‡å°‘ä¸­é—´è¾“å‡ºçš„log
    # ====================================================================================================
    # 2.1 åˆå§‹åŒ–
    # ====================================================================================================
    result_folder = conf.get_result_folder()  # é€‰å¸ç»“æœæ–‡ä»¶å¤¹

    if not multi_process:
        for strategy in conf.strategy_list:
            process_strategy(strategy, result_folder)
        return

    # å¤šè¿›ç¨‹æ¨¡å¼
    with ProcessPoolExecutor(max_workers=job_num) as executor:
        futures = [executor.submit(process_strategy, stg, result_folder) for stg in conf.strategy_list]

        for future in as_completed(futures):
            try:
                future.result()
            except Exception as e:
                logger.exception(e)
                exit(1)


def select_coins(confs: BacktestConfig | List[BacktestConfig], multi_process=True):
    if isinstance(confs, BacktestConfig):
        # å¦‚æœæ˜¯å•ä¾‹ï¼Œå°±ç›´æ¥è¿”å›åŸæ¥çš„ç»“æœ
        return select_coin_with_conf(confs, multi_process=multi_process)

    # å¦åˆ™å°±ç›´æ¥å¹¶è¡Œå›æµ‹
    is_multi = False  # æ€•èµ„æºæº¢å‡ºï¼Œå¼ºåˆ¶ä¸²è¡Œ
    is_silent = True  # å‡å°‘è¾“å‡º
    with ProcessPoolExecutor(max_workers=job_num) as executor:
        futures = [executor.submit(select_coin_with_conf, conf, is_multi, is_silent) for conf in confs]
        for future in tqdm(as_completed(futures), total=len(confs), desc='é€‰å¸'):
            try:
                future.result()
            except Exception as e:
                logger.exception(e)
                exit(1)


# endregion

# ======================================================================================
# é€‰å¸ç»“æœèšåˆ
# ======================================================================================
# region é€‰å¸ç»“æœèšåˆ
def transfer_swap(select_coin, df_swap):
    """
    å°†ç°è´§ä¸­çš„æ•°æ®æ›¿æ¢æˆåˆçº¦æ•°æ®ï¼Œä¸»è¦æ›¿æ¢ï¼šclose
    :param select_coin:     é€‰å¸æ•°æ®
    :param df_swap:         åˆçº¦æ•°æ®
    :return:
    """
    trading_cols = ['symbol', 'is_spot', 'close', 'next_close']

    # æ‰¾åˆ°æˆ‘ä»¬é€‰å¸ç»“æœä¸­ï¼Œæ‰¾åˆ°æœ‰å¯¹åº”åˆçº¦çš„ç°è´§é€‰å¸
    spot_line_index = select_coin[(select_coin['symbol_swap'] != '') & (select_coin['is_spot'] == 1)].index
    spot_select_coin = select_coin.loc[spot_line_index].copy()

    # å…¶ä»–çš„é€‰å¸ï¼Œä¹Ÿå°±æ˜¯è¦ä¹ˆå·²ç»æ˜¯åˆçº¦ï¼Œè¦ä¹ˆæ˜¯ç°è´§ä½†æ˜¯æ‰¾ä¸åˆ°åˆçº¦
    swap_select_coin = select_coin.loc[select_coin.index.difference(spot_line_index)].copy()

    # åˆå¹¶åˆçº¦æ•°æ®ï¼Œæ‰¾åˆ°å¯¹åº”çš„åˆçº¦ï¼ˆåŸå§‹æ•°æ®ä¸åŠ¨ï¼Œæ–°å¢_2ï¼‰
    # ['candle_begin_time', 'symbol_swap', 'strategy', 'cap_weight', 'æ–¹å‘', 'offset', 'target_alloc_ratio']
    spot_select_coin = pd.merge(
        spot_select_coin, df_swap[['candle_begin_time', *trading_cols]],
        left_on=['candle_begin_time', 'symbol_swap'], right_on=['candle_begin_time', 'symbol'],
        how='left', suffixes=('', '_2'))

    # mergeå®Œæˆä¹‹åï¼Œå¯èƒ½å› ä¸ºæœ‰äº›åˆçº¦æ•°æ®ä¸Šçº¿ä¸è¶…è¿‡æŒ‡å®šçš„æ—¶é—´ï¼ˆmin_kline_numï¼‰,é€ æˆåˆå¹¶å¼‚å¸¸ï¼Œéœ€è¦æŒ‰ç…§åŸç°è´§é€»è¾‘æ‰§è¡Œ
    failed_merge_select_coin = spot_select_coin[spot_select_coin['close_2'].isna()][select_coin.columns].copy()

    spot_select_coin = spot_select_coin.dropna(subset=['close_2'], how='any')
    spot_select_coin['is_spot_2'] = spot_select_coin['is_spot_2'].astype(np.int8)

    spot_select_coin.drop(columns=trading_cols, inplace=True)
    rename_dict = {f'{trading_col}_2': trading_col for trading_col in trading_cols}
    spot_select_coin.rename(columns=rename_dict, inplace=True)

    # å°†æ‹†åˆ†çš„é€‰å¸æ•°æ®ï¼Œåˆå¹¶å›å»
    # 1. çº¯åˆçº¦éƒ¨åˆ†ï¼Œæˆ–è€…æ²¡æœ‰åˆçº¦çš„ç°è´§ 2. ä¸èƒ½è½¬æ¢çš„ç°è´§ 3. ç°è´§è¢«æ›¿æ¢ä¸ºåˆçº¦çš„éƒ¨åˆ†
    select_coin = pd.concat([swap_select_coin, failed_merge_select_coin, spot_select_coin], axis=0)
    select_coin.sort_values(['candle_begin_time', 'æ–¹å‘'], inplace=True)

    return select_coin


def concat_select_results(conf: BacktestConfig) -> None:
    """
    èšåˆç­–ç•¥é€‰å¸ç»“æœï¼Œå½¢æˆç»¼åˆé€‰å¸ç»“æœ
    :param conf:
    :return:
    """
    # å¦‚æœæ˜¯çº¯å¤šå¤´ç°è´§æ¨¡å¼ï¼Œé‚£ä¹ˆå°±ä¸è½¬æ¢åˆçº¦æ•°æ®ï¼Œåªä¸‹ç°è´§å•
    all_select_result_df_list = []  # å­˜å‚¨æ¯ä¸€ä¸ªç­–ç•¥çš„é€‰å¸ç»“æœ
    result_folder = conf.get_result_folder()
    select_result_path = result_folder / 'é€‰å¸ç»“æœ.pkl'

    for strategy in conf.strategy_list:
        stg_select_result = result_folder / f'{strategy.get_fullname(as_folder_name=True)}.pkl'

        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°±è·³è¿‡
        if not os.path.exists(stg_select_result):
            continue

        all_select_result_df_list.append(pd.read_pickle(stg_select_result))

    # å¦‚æœæ²¡æœ‰ä»»ä½•ç­–ç•¥çš„é€‰å¸ç»“æœï¼Œå°±ç›´æ¥è¿”å›
    if not all_select_result_df_list:
        pd.DataFrame(columns=SELECT_RES_COLS).to_pickle(select_result_path)
        return

    # èšåˆé€‰å¸ç»“æœ
    all_select_result_df = pd.concat(all_select_result_df_list, ignore_index=True)
    del all_select_result_df_list
    gc.collect()
    all_select_result_df.to_pickle(select_result_path)


def process_select_results(conf: BacktestConfig) -> pd.DataFrame:
    select_result_path = conf.get_result_folder() / 'é€‰å¸ç»“æœ.pkl'
    if not select_result_path.exists():
        logger.warning('æ²¡æœ‰ç”Ÿæˆé€‰å¸æ–‡ä»¶ï¼Œç›´æ¥è¿”å›')
        return pd.DataFrame(columns=SELECT_RES_COLS)
    all_select_result_df = pd.read_pickle(select_result_path)

    if conf.is_use_spot:
        # å¦‚æœç°è´§éƒ¨åˆ†æœ‰å¯¹åº”çš„åˆçº¦ï¼Œæˆ‘ä»¬ä¼šæŠŠç°è´§æ¯”å¯¹æ›¿æ¢ä¸ºå¯¹åº”çš„åˆçº¦ï¼Œæ¥èŠ‚çœæ‰‹ç»­è´¹ï¼ˆåˆçº¦äº¤æ˜“æ‰‹ç»­è´¹æ¯”ç°è´§è¦ä½ï¼‰
        all_kline_df = pd.read_pickle(get_file_path(*ALL_KLINE_PATH_TUPLE))
        # å°†å«æœ‰ç°è´§çš„å¸ç§ï¼Œæ›¿æ¢æ‰å…¶ä¸­closeä»·æ ¼
        df_swap = all_kline_df[(all_kline_df['is_spot'] == 0) & (all_kline_df['symbol_spot'] != '')]
        all_select_result_df = transfer_swap(all_select_result_df, df_swap)

    return all_select_result_df


def to_ratio_pivot(df_select: pd.DataFrame, candle_begin_times, columns) -> pd.DataFrame:
    # è½¬æ¢ä¸ºä»“ä½æ¯”ä¾‹ï¼Œindex ä¸ºæ—¶é—´ï¼Œcolumns ä¸ºå¸ç§ï¼Œvalues ä¸ºæ¯”ä¾‹çš„æ±‚å’Œ
    df_ratio = df_select.pivot_table(
        index='candle_begin_time', columns=columns, values='target_alloc_ratio',
        fill_value=0, aggfunc='sum', observed=True
    )

    # é‡æ–°å¡«å……ä¸ºå®Œæ•´çš„å°æ—¶çº§åˆ«æ•°æ®
    df_ratio = df_ratio.reindex(candle_begin_times, fill_value=0)
    return df_ratio


def trim_ratio_delists(df_ratio: pd.DataFrame, end_time: pd.Timestamp, market_dict: dict, trade_type: str):
    """
    ** åˆ é™¤è¦ä¸‹æ¶çš„å¸ **
    å½“å¸ç§å³å°†ä¸‹æ¶çš„æ—¶å€™ï¼ŒæŠŠåç»­çš„æŒä»“è°ƒæ•´ä¸º 0
    :param df_ratio: ä»“ä½æ¯”ä¾‹
    :param end_time: å›æµ‹ç»“æŸæ—¶é—´
    :param market_dict: æ‰€æœ‰å¸ç§çš„Kçº¿æ•°æ®
    :param trade_type: spot or swap
    :return: ä»“ä½è°ƒæ•´åçš„æ¯”ä¾‹
    """
    for symbol in df_ratio.columns:
        df_market = market_dict[symbol]
        if len(df_market) < 2:
            continue

        # æ²¡æœ‰ä¸‹æ¶
        last_end_time = df_market['candle_begin_time'].iloc[-1]
        if last_end_time >= end_time:
            continue

        second_last_end_time = df_market['candle_begin_time'].iloc[-2]
        if (df_ratio.loc[second_last_end_time:, symbol].abs() > 1e-8).any():
            logger.warning(f'{trade_type} {symbol} ä¸‹æ¶é€‰å¸æƒé‡ä¸ä¸º 0ï¼Œæ¸…é™¤ {second_last_end_time} ä¹‹åçš„æƒé‡')
            df_ratio.loc[second_last_end_time:, symbol] = 0

    return df_ratio


def agg_offset_by_strategy(df_select: pd.DataFrame, stg_conf: StrategyConfig):
    # å¦‚æœæ²¡æœ‰ç°è´§é€‰å¸ç»“æœï¼Œå°±è¿”å›ç©º
    if df_select.empty:
        return pd.DataFrame(columns=['candle_begin_time', 'symbol', 'target_alloc_ratio'])

    # è½¬æ¢spotå’Œswapçš„é€‰å¸æ•°æ®ä¸ºé€è§†è¡¨ï¼Œä»¥candle_begin_timeä¸ºindexï¼Œsymbolä¸ºcolumnsï¼Œvaluesä¸ºtarget_alloc_ratioçš„sum
    # æ³¨ï¼šå¤šç­–ç•¥çš„ç›¸åŒå‘¨æœŸçš„ç›¸åŒé€‰å¸ï¼Œä¼šåœ¨è¿™ä¸ªæ­¥éª¤è¢«èšåˆæƒé‡
    df_ratio = df_select.pivot(index='candle_begin_time', columns='symbol', values='target_alloc_ratio')

    # æ„å»ºcandle_begin_timeåºåˆ—
    candle_begin_times = pd.date_range(
        df_select['candle_begin_time'].min(), df_select['candle_begin_time'].max(), freq='H', inclusive='both')
    df_ratio = df_ratio.reindex(candle_begin_times, fill_value=0)

    # å¤šoffsetçš„æƒé‡èšåˆ
    df_ratio = df_ratio.rolling(stg_conf.hold_period, min_periods=1).sum()

    # æ¢å¤ candle_begin_time, symbol, target_alloc_ratioçš„dfç»“æ„
    df_ratio = df_ratio.stack().reset_index(name='target_alloc_ratio')
    df_ratio.rename(columns={'level_0': 'candle_begin_time'}, inplace=True)

    return df_ratio


def agg_multi_strategy_ratio(conf: BacktestConfig, df_select: pd.DataFrame):
    """
    èšåˆå¤šoffsetã€å¤šç­–ç•¥é€‰å¸ç»“æœä¸­çš„target_alloc_ratio
    :param conf: å›æµ‹é…ç½®
    :param df_select: é€‰å¸ç»“æœ
    :return: èšåˆåçš„df_spot_ratio å’Œ df_swap_ratioã€‚

    æ•°æ®ç»“æ„:
    - index_colä¸ºcandle_begin_timeï¼Œ
    - columnsä¸ºsymbolï¼Œ
    - valuesä¸ºtarget_alloc_ratioçš„èšåˆç»“æœ

    ç¤ºä¾‹:
                    1000BONK-USDT	1000BTTC-USDT	1000FLOKI-USDT	1000LUNC-USDT	1000PEPE-USDT	1000RATS-USDT	1000SATS-USDT	1000SHIB-USDT	1000XEC-USDT	1INCH-USDT	AAVE-USDT	ACE-USDT	ADA-USDT	    AEVO-USDT   ...
    2021/1/1 00:00	0	            0	            0	            0	            0	            0	            0	            0	            0	            0	        0	        0	        -0.083333333	0           ...
    2021/1/1 01:00	0	            0	            0	            0	            0	            0	            0	            0	            0	            0	        0	        0	        -0.083333333	0           ...
    2021/1/1 02:00	0	            0	            0	            0	            0	            0	            0	            0	            0	            0	        0	        0	        -0.083333333	0           ...
    2021/1/1 03:00	0	            0	            0	            0	            0	            0	            0	            0	            0	            0	        0	        0	        -0.083333333	0           ...
    2021/1/1 04:00	0	            0	            0	            0	            0	            0	            0	            0	            0	            0	        0	        0	        -0.083333333	0           ...
    2021/1/1 05:00	0	            0	            0	            0	            0	            0	            0	            0	            0	            0	        0	        0	        -0.083333333	0           ...
    2021/1/1 06:00	0	            0	            0	            0	            0	            0	            0	            0	            0	            0	        0	        0	        -0.083333333	0           ...
    2021/1/1 07:00	0	            0	            0	            0	            0	            0	            0	            0	            0	            0	        0	        0	        -0.083333333	0           ...
    2021/1/1 08:00	0	            0	            0	            0	            0	            0	            0	            0	            0	            0	        0	        0	        -0.083333333	0           ...
    2021/1/1 09:00	0	            0	            0	            0	            0	            0	            0	            0	            0	            0	        0	        0	        -0.083333333	0           ...
    """
    # ====================================================================================================
    # 1. å…ˆé’ˆå¯¹æ¯ä¸ªç­–ç•¥çš„å¤šoffsetè¿›è¡Œèšåˆ
    # ====================================================================================================
    df_spot_select_list = []
    df_swap_select_list = []

    # å¦‚æœæ˜¯Dçš„æŒä»“å‘¨æœŸï¼Œåº”è¯¥æ˜¯å½“å¤©çš„é€‰å¸ï¼Œç¬¬äºŒå¤©0ç‚¹æŒä»“ã€‚
    # æŒ‰ç…§ç›®å‰çš„é€»è¾‘ï¼ŒåŸæ¥è‡ªå¸¦çš„begin timeæ˜¯0ç‚¹
    if conf.is_day_period:
        df_select['candle_begin_time'] = df_select['candle_begin_time'] + pd.Timedelta(hours=23)

    for stg_conf in conf.strategy_list:
        # è£åˆ‡å½“å‰ç­–ç•¥çš„spoté€‰å¸ç»“æœ
        df_select_spot = df_select[(df_select['strategy'] == stg_conf.name) & (df_select['is_spot'] == 1)]
        # ä¹°å…¥ç°è´§éƒ¨åˆ†
        _spot_select_long = agg_offset_by_strategy(df_select_spot[df_select_spot['æ–¹å‘'] == 1], stg_conf)
        df_spot_select_list.append(_spot_select_long)
        # åšç©ºç°è´§éƒ¨åˆ†
        _spot_select_short = agg_offset_by_strategy(df_select_spot[df_select_spot['æ–¹å‘'] == -1], stg_conf)
        df_spot_select_list.append(_spot_select_short)

        # è£åˆ‡å½“å‰ç­–ç•¥çš„swapé€‰å¸ç»“æœ
        df_select_swap = df_select[(df_select['strategy'] == stg_conf.name) & (df_select['is_spot'] == 0)]
        # ä¹°å…¥åˆçº¦éƒ¨åˆ†
        _swap_select_long = agg_offset_by_strategy(df_select_swap[df_select_swap['æ–¹å‘'] == 1], stg_conf)
        df_swap_select_list.append(_swap_select_long)
        # åšç©ºåˆçº¦éƒ¨åˆ†
        _swap_select_short = agg_offset_by_strategy(df_select_swap[df_select_swap['æ–¹å‘'] == -1], stg_conf)
        df_swap_select_list.append(_swap_select_short)

    df_spot_select = pd.concat(df_spot_select_list, ignore_index=True)
    df_swap_select = pd.concat(df_swap_select_list, ignore_index=True)

    # ====================================================================================================
    # 2. é’ˆå¯¹å¤šç­–ç•¥è¿›è¡Œèšåˆ
    # ====================================================================================================
    # æ„å»ºcandle_begin_timeåºåˆ—ï¼Œä¸ç®¡æ˜¯Dè¿˜æ˜¯Hçš„æŒä»“å‘¨æœŸï¼Œéƒ½ä»¥Hä¸ºå‡†
    candle_begin_times = pd.date_range(conf.start_date, conf.end_date, freq='H', inclusive='left')

    # è½¬æ¢spotå’Œswapçš„é€‰å¸æ•°æ®ä¸ºé€è§†è¡¨ï¼Œä»¥candle_begin_timeä¸ºindexï¼Œsymbolä¸ºcolumnsï¼Œvaluesä¸ºtarget_alloc_ratioçš„sum
    # æ³¨ï¼šå¤šç­–ç•¥çš„ç›¸åŒå‘¨æœŸçš„ç›¸åŒé€‰å¸ï¼Œä¼šåœ¨è¿™ä¸ªæ­¥éª¤è¢«èšåˆæƒé‡
    df_spot_ratio = to_ratio_pivot(df_spot_select, candle_begin_times, 'symbol')
    df_swap_ratio = to_ratio_pivot(df_swap_select, candle_begin_times, 'symbol')

    # # é’ˆå¯¹ä¸‹æ¶å¸çš„å¤„ç†
    # df_spot_ratio = trim_ratio_delists(df_spot_ratio, candle_begin_times.max(), spot_dict, 'spot')
    # df_swap_ratio = trim_ratio_delists(df_swap_ratio, candle_begin_times.max(), swap_dict, 'swap')

    return df_spot_ratio, df_swap_ratio
