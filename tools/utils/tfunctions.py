# -*- coding: utf-8 -*-
"""
é‚¢ä¸è¡Œï½œç­–ç•¥åˆ†äº«ä¼š
é€‰å¸ç­–ç•¥æ¡†æž¶ð“Ÿð“»ð“¸

ç‰ˆæƒæ‰€æœ‰ Â©ï¸ é‚¢ä¸è¡Œ
å¾®ä¿¡: xbx1717

æœ¬ä»£ç ä»…ä¾›ä¸ªäººå­¦ä¹ ä½¿ç”¨ï¼Œæœªç»æŽˆæƒä¸å¾—å¤åˆ¶ã€ä¿®æ”¹æˆ–ç”¨äºŽå•†ä¸šç”¨é€”ã€‚

Author: é‚¢ä¸è¡Œ
"""
import os
import time
from functools import reduce
from itertools import combinations
from pathlib import Path
from typing import List, Union

import numpy as np
import pandas as pd


def _calculate_group_returns(df: pd.DataFrame, factor_name: str, bins: int, method: str = 'val'):
    """åˆ†ç»„æ”¶ç›Šè®¡ç®—å†…éƒ¨å‡½æ•°"""

    # å› å­æŽ’åº
    df['total_coins'] = df.groupby('candle_begin_time')['symbol'].transform('size')

    # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
    valid_df = df[df['total_coins'] >= bins].copy()

    if method == 'pct':
        valid_df['rank'] = valid_df.groupby('candle_begin_time')[factor_name].rank(method='first')
        # åˆ†ç»„å¤„ç†
        labels = [f'ç¬¬{i}ç»„' for i in range(1, bins + 1)]
        valid_df['groups'] = valid_df.groupby('candle_begin_time')['rank'].transform(
            lambda x: pd.qcut(x, q=bins, labels=labels, duplicates='drop')
        )
    elif method == 'val':
        # ä½¿ç”¨å…¨åŽ†å²æ•°æ®è®¡ç®—åˆ†ç®±è¾¹ç•Œ
        all_values = df[factor_name].dropna()
        if all_values.empty:
            raise ValueError("å› å­æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—åˆ†ç®±è¾¹ç•Œ")
        # è®¡ç®—åˆ†ç®±è¾¹ç•Œ
        _, bins_edges = pd.cut(all_values, bins=bins, retbins=True)
        # ç”Ÿæˆå¸¦æ•°å€¼èŒƒå›´çš„æ ‡ç­¾
        labels = []
        for i in range(len(bins_edges) - 1):
            left_edge = round(bins_edges[i], 4)
            right_edge = round(bins_edges[i + 1], 4)
            # ç¬¬ä¸€ä¸ªåŒºé—´å·¦é—­åˆï¼Œå…¶ä»–å·¦å¼€å³é—­åˆ
            left_bracket = '[' if i == 0 else '('
            labels.append(f'ç¬¬{i + 1}ç»„{left_bracket}{left_edge}-{right_edge}]')
        # åº”ç”¨åˆ†ç®±
        valid_df['groups'] = pd.cut(valid_df[factor_name], bins=bins_edges, labels=labels, include_lowest=True,
                                    duplicates='drop')

    # è®¡ç®—æ”¶ç›Š
    valid_df['ret_next'] = valid_df['next_close'] / valid_df['close'] - 1
    group_returns = valid_df.groupby(['candle_begin_time', 'groups'])['ret_next'].mean().to_frame()
    group_returns.reset_index('groups', inplace=True)
    group_returns['groups'] = group_returns['groups'].astype(str)

    return labels, group_returns


def group_analysis(df: pd.DataFrame, factor_name: str, bins: int = 10, method: str = 'val'):
    """
    :param df: åŒ…å«åˆ†æžæ•°æ®çš„DataFrame
    :param factor_name: è¦åˆ†æžçš„å› å­åç§°
    :param bins: åˆ†ç»„æ•°é‡ï¼Œ0è¡¨ç¤ºä¸åˆ†æž
    :param method: åˆ†ç®±æ–¹æ³•ï¼Œ'quantile'ï¼ˆåˆ†ä½æ•°ï¼‰æˆ–'cut'ï¼ˆç­‰å®½åˆ†ç®±ï¼‰
    :raises ValueError: è¾“å…¥æ•°æ®ä¸ç¬¦åˆè¦æ±‚æ—¶æŠ›å‡º
    """
    if bins == 0:
        raise ValueError("é”™è¯¯ï¼šåˆ†ç®±ä¸ªæ•°ä¸èƒ½ä¸º0ï¼Œè¯·è®¾ç½®binsâ‰¥1çš„æ•´æ•°å€¼")

    # å‚æ•°éªŒè¯
    if method not in ['pct', 'val']:
        raise ValueError("methodå‚æ•°å¿…é¡»ä¸º'pct'æˆ–'val'")

    # éªŒè¯è¾“å…¥æ•°æ®
    required_columns = ['candle_begin_time', 'symbol', 'close', 'next_close']
    if not all(col in df.columns for col in required_columns):
        missing = [col for col in required_columns if col not in df.columns]
        raise ValueError(f"è¾“å…¥æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing}")

    # åˆ†ç»„ç»“æžœï¼ˆä¼ å…¥methodå‚æ•°ï¼‰
    labels, group_returns = _calculate_group_returns(df, factor_name, bins, method)

    # åˆ†ç»„æ•´åˆ
    group_returns = group_returns.reset_index()
    group_returns = pd.pivot(group_returns,
                             index='candle_begin_time',
                             columns='groups',
                             values='ret_next')
    group_curve = (group_returns + 1).cumprod()
    group_curve = group_curve[labels]

    first_bin_label = labels[0]
    last_bin_label = labels[-1]
    # å¤šç©ºé€»è¾‘åˆ¤æ–­
    if group_curve[first_bin_label].iloc[-1] > group_curve[last_bin_label].iloc[-1]:
        ls_ret = (group_returns[first_bin_label] - group_returns[last_bin_label]) / 2
    else:
        ls_ret = (group_returns[last_bin_label] - group_returns[first_bin_label]) / 2

    group_curve['å¤šç©ºå‡€å€¼'] = (ls_ret + 1).cumprod()
    group_curve = group_curve.fillna(method='ffill')
    bar_df = group_curve.iloc[-1].reset_index()
    bar_df.columns = ['groups', 'asset']

    return group_curve, bar_df, labels


def coins_difference_all_pairs(root_path: Union[str, Path], strategies_list: List[str]):
    """è®¡ç®—æ‰€æœ‰ç­–ç•¥ä¸¤ä¸¤ä¹‹é—´çš„é€‰å¸ç›¸ä¼¼åº¦è¯¦ç»†ç»“æžœ"""
    root_path = Path(root_path)

    # è¯»å–æ‰€æœ‰ç­–ç•¥çš„é€‰å¸ç»“æžœï¼Œå¹¶è½¬æ¢ä¸ºæŒ‰æ—¶é—´ç‚¹çš„é›†åˆ
    print("å¼€å§‹è¯»å–ç­–ç•¥é€‰å¸ç»“æžœ")
    strategies = {}
    for strategy in strategies_list:
        s_path = os.path.join(root_path, f'data/å›žæµ‹ç»“æžœ/{strategy}/final_select_results.pkl')
        s = pd.read_pickle(s_path)
        if s.empty:
            raise ValueError(f"{strategy}å¯¹åº”é€‰å¸ç»“æžœä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
        s_grouped = s.groupby('candle_begin_time')['symbol'].apply(set).rename(strategy)
        strategies[strategy] = s_grouped

    # åˆå¹¶æ‰€æœ‰ç­–ç•¥çš„æ•°æ®ï¼Œä½¿ç”¨outer joinç¡®ä¿åŒ…å«æ‰€æœ‰æ—¶é—´ç‚¹
    df = pd.DataFrame(index=pd.Index([], name='candle_begin_time'))
    for strategy, s in strategies.items():
        df = df.join(s.rename(strategy), how='outer')
    df = df.reset_index()

    # ç”Ÿæˆæ‰€æœ‰ä¸¤ä¸¤ç­–ç•¥ç»„åˆ
    strategy_pairs = list(combinations(strategies_list, 2))
    results = []

    for strat1, strat2 in strategy_pairs:
        print(f"æ­£åœ¨åˆ†æž{strat1}å’Œ{strat2}ä¹‹é—´çš„ç›¸ä¼¼åº¦")

        # æå–ç­–ç•¥å¯¹æ•°æ®
        pair_df = df[['candle_begin_time', strat1, strat2]].copy()

        # è€ƒè™‘åˆ°ç­–ç•¥å›žæµ‹æ—¶é—´ä¸åŒï¼ŒåŽ»é™¤nanå€¼
        pair_df = pair_df.dropna()

        if pair_df.empty:
            print(f'ðŸ”” {strat1}å’Œ{strat2} å›žæµ‹æ—¶é—´æ— äº¤é›†ï¼Œéœ€è¦æ ¸å®žç­–ç•¥å›žæµ‹config')
            results.append((strat1, strat2, np.nan))
            continue

        # è®¡ç®—äº¤é›†åŠé€‰å¸æ•°é‡
        pair_df['äº¤é›†'] = pair_df.apply(lambda x: x[strat1] & x[strat2], axis=1)
        pair_df[f'{strat1}é€‰å¸æ•°é‡'] = pair_df[strat1].apply(len)
        pair_df[f'{strat2}é€‰å¸æ•°é‡'] = pair_df[strat2].apply(len)
        pair_df['é‡å¤é€‰å¸æ•°é‡'] = pair_df['äº¤é›†'].apply(len)

        # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆå¤„ç†åˆ†æ¯ä¸ºé›¶çš„æƒ…å†µï¼‰
        def calc_similarity(row, base_strat, other_strat):
            base_count = row[f'{base_strat}é€‰å¸æ•°é‡']
            other_count = row[f'{other_strat}é€‰å¸æ•°é‡']
            if base_count == 0:
                return 1.0 if other_count == 0 else np.nan
            return row['é‡å¤é€‰å¸æ•°é‡'] / base_count

        pair_df[f'ç›¸ä¼¼åº¦_åŸºäºŽ{strat1}'] = pair_df.apply(
            lambda x: calc_similarity(x, strat1, strat2), axis=1)
        pair_df[f'ç›¸ä¼¼åº¦_åŸºäºŽ{strat2}'] = pair_df.apply(
            lambda x: calc_similarity(x, strat2, strat1), axis=1)
        similarity = np.nanmean((pair_df[f'ç›¸ä¼¼åº¦_åŸºäºŽ{strat1}'] + pair_df[f'ç›¸ä¼¼åº¦_åŸºäºŽ{strat2}']) / 2)

        results.append((strat1, strat2, similarity))

    return results


def curve_difference_all_pairs(root_path: Union[str, Path], strategies_list: List[str]) -> pd.DataFrame:
    """èŽ·å–æ‰€æœ‰ç­–ç•¥èµ„é‡‘æ›²çº¿ç»“æžœ"""
    root_path = Path(root_path)

    # è¯»å–æ‰€æœ‰ç­–ç•¥çš„èµ„é‡‘æ›²çº¿ç»“æžœï¼Œå¹¶è½¬æ¢ä¸ºæŒ‰æ—¶é—´ç‚¹çš„é›†åˆ
    print("å¼€å§‹è¯»å–ç­–ç•¥èµ„é‡‘æ›²çº¿")
    strategies = {}
    for strategy in strategies_list:
        s_path = os.path.join(root_path, f'data/å›žæµ‹ç»“æžœ/{strategy}/èµ„é‡‘æ›²çº¿.csv')
        s = pd.read_csv(s_path, encoding='utf-8-sig', parse_dates=['candle_begin_time'])
        if s.empty:
            raise ValueError(f"{strategy}èµ„é‡‘æ›²çº¿ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
        s = s.rename(columns={'æ¶¨è·Œå¹…': f'{strategy}'})
        strategies[strategy] = s[['candle_begin_time', f'{strategy}']]

    # åˆå¹¶æ‰€æœ‰ç­–ç•¥çš„æ•°æ®ï¼Œä½¿ç”¨outer joinç¡®ä¿åŒ…å«æ‰€æœ‰æ—¶é—´ç‚¹
    df = reduce(
        lambda left, right: pd.merge(left, right, on='candle_begin_time', how='outer'),
        strategies.values()
    )

    return df.set_index('candle_begin_time')


def process_equity_data(root_path, backtest_name, start_time, end_time):
    """
    å¤„ç†å›žæµ‹å’Œå®žç›˜èµ„é‡‘æ›²çº¿æ•°æ®ï¼Œå¹¶è®¡ç®—å¯¹æ¯”æ¶¨è·Œå¹…å’Œèµ„é‡‘æ›²çº¿ã€‚

    å‚æ•°:
    - root_path: æ ¹è·¯å¾„
    - backtest_name: å›žæµ‹ç»“æžœæ–‡ä»¶å¤¹åç§°
    - start_time: å¼€å§‹æ—¶é—´ï¼ˆdatetime æˆ–å­—ç¬¦ä¸²ï¼‰
    - end_time: ç»“æŸæ—¶é—´ï¼ˆdatetime æˆ–å­—ç¬¦ä¸²ï¼‰

    è¿”å›ž:
    - df: åŒ…å«å›žæµ‹å’Œå®žç›˜èµ„é‡‘æ›²çº¿çš„ DataFrame
    """
    # è¯»å–å›žæµ‹èµ„é‡‘æ›²çº¿
    backtest_equity = pd.read_csv(
        os.path.join(root_path, f'data/å›žæµ‹ç»“æžœ/{backtest_name}/èµ„é‡‘æ›²çº¿.csv'),
        encoding='utf-8-sig',
        parse_dates=['candle_begin_time']
    )
    # è¿‡æ»¤æ—¶é—´èŒƒå›´
    backtest_equity = backtest_equity[
        (backtest_equity['candle_begin_time'] >= start_time) &
        (backtest_equity['candle_begin_time'] <= end_time)
        ]

    if backtest_equity.empty:
        raise ValueError("å›žæµ‹èµ„é‡‘æ›²çº¿ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ 'start_time' å’Œ 'end_time' çš„è®¾ç½®")

    # è®¡ç®—å‡€å€¼
    backtest_equity['å‡€å€¼'] = backtest_equity['å‡€å€¼'] / backtest_equity['å‡€å€¼'].iloc[0]
    # é‡å‘½ååˆ—
    backtest_equity = backtest_equity.rename(
        columns={'æ¶¨è·Œå¹…': 'å›žæµ‹æ¶¨è·Œå¹…', 'å‡€å€¼': 'å›žæµ‹å‡€å€¼', 'candle_begin_time': 'time'}
    )

    # è¯»å–å®žç›˜èµ„é‡‘æ›²çº¿
    trading_equity = pd.read_csv(
        os.path.join(root_path, f'data/å›žæµ‹ç»“æžœ/{backtest_name}/å®žç›˜ç»“æžœ/è´¦æˆ·ä¿¡æ¯/equity.csv'),
        encoding='gbk',
        parse_dates=['time']
    )

    # è°ƒæ•´æ—¶é—´åç§»
    utc_offset = int(time.localtime().tm_gmtoff / 60 / 60) + 1
    trading_equity['time'] = trading_equity['time'] - pd.Timedelta(f'{utc_offset}H')
    # æ ¼å¼åŒ–æ—¶é—´
    trading_equity['time'] = trading_equity['time'].map(lambda x: x.strftime('%Y-%m-%d %H:00:00'))
    trading_equity['time'] = pd.to_datetime(trading_equity['time'])
    # è¿‡æ»¤æ—¶é—´èŒƒå›´
    trading_equity = trading_equity[
        (trading_equity['time'] >= start_time) &
        (trading_equity['time'] <= end_time)
        ]

    if trading_equity.empty:
        raise ValueError("å®žç›˜èµ„é‡‘æ›²çº¿ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ 'start_time' å’Œ 'end_time' çš„è®¾ç½®")

    # è®¡ç®—å®žç›˜å‡€å€¼
    trading_equity['å®žç›˜å‡€å€¼'] = trading_equity['è´¦æˆ·æ€»å‡€å€¼'] / trading_equity['è´¦æˆ·æ€»å‡€å€¼'].iloc[0]
    # è®¡ç®—å®žç›˜æ¶¨è·Œå¹…
    trading_equity['å®žç›˜æ¶¨è·Œå¹…'] = trading_equity['å®žç›˜å‡€å€¼'].pct_change()
    # åˆå¹¶å›žæµ‹å’Œå®žç›˜æ•°æ®
    df = pd.merge(trading_equity, backtest_equity, on='time', how='inner')
    if df.empty:
        raise ValueError("å›žæµ‹å’Œå®žç›˜æ›²çº¿æ—¶é—´æ— æ³•å¯¹é½ï¼Œè¯·æ£€æŸ¥æ•°æ®")

    # è®¡ç®—å¯¹æ¯”æ¶¨è·Œå¹…
    df['å¯¹æ¯”æ¶¨è·Œå¹…'] = (df['å®žç›˜æ¶¨è·Œå¹…'] - df['å›žæµ‹æ¶¨è·Œå¹…']) / 2
    # è®¡ç®—å¯¹æ¯”èµ„é‡‘æ›²çº¿
    df['å¯¹æ¯”èµ„é‡‘æ›²çº¿'] = (df['å¯¹æ¯”æ¶¨è·Œå¹…'] + 1).cumprod()

    return df


def process_coin_selection_data(root_path, backtest_name, start_time, end_time):
    """
    å¤„ç†å›žæµ‹å’Œå®žç›˜é€‰å¸æ•°æ®ï¼Œå¹¶è®¡ç®—é€‰å¸çš„äº¤é›†ã€å¹¶é›†ã€ç›¸ä¼¼åº¦ç­‰æŒ‡æ ‡ã€‚

    å‚æ•°:
    - root_path: æ ¹è·¯å¾„
    - backtest_name: å›žæµ‹ç»“æžœæ–‡ä»¶å¤¹åç§°
    - trading_name: å®žç›˜èµ„é‡‘æ›²çº¿æ–‡ä»¶å¤¹åç§°
    - hour_offset: æ—¶é—´åç§»é‡

    è¿”å›ž:
    - merged: åŒ…å«å›žæµ‹å’Œå®žç›˜é€‰å¸æ•°æ®çš„ DataFrame
    """
    # è¯»å–å›žæµ‹é€‰å¸æ•°æ®
    backtest_coins = pd.read_pickle(os.path.join(root_path, f'data/å›žæµ‹ç»“æžœ/{backtest_name}/final_select_results.pkl'))
    # è¿‡æ»¤æ—¶é—´èŒƒå›´
    backtest_coins = backtest_coins[
        (backtest_coins['candle_begin_time'] >= start_time) &
        (backtest_coins['candle_begin_time'] <= end_time)
        ]
    if backtest_coins.empty:
        raise ValueError("å›žæµ‹é€‰å¸æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ 'start_time' å’Œ 'end_time' çš„è®¾ç½®")

    # ç›®çš„æ˜¯å’Œå®žç›˜symbolå¯¹é½ï¼Œå®žç›˜çš„symbolæ²¡æœ‰è¿žå­—ç¬¦ï¼Œæ¯”å¦‚å›žæµ‹symbol 'BTC-USDT'ï¼Œå®žç›˜å¯¹åº”çš„symbolä¸º 'BTCUSDT'
    backtest_coins['symbol'] = backtest_coins['symbol'].astype(str)
    backtest_coins['symbol'] = backtest_coins['symbol'].apply(lambda x: x.replace('-', ''))

    # è¯»å–å®žç›˜é€‰å¸æ•°æ®
    trading_coins = pd.DataFrame()
    path = os.path.join(root_path, f'data/å›žæµ‹ç»“æžœ/{backtest_name}/å®žç›˜ç»“æžœ/select_coin')
    pkl_files = [f for f in os.listdir(path) if f.endswith('.pkl')]
    if len(pkl_files) == 0:
        raise ValueError("å¯¹åº”æ–‡ä»¶å¤¹ä¸‹æ²¡æœ‰ç›¸å…³æ€§çš„å®žç›˜é€‰å¸æ•°æ®ï¼Œè¯·æ£€æŸ¥")
    for pkl_file in pkl_files:
        pkl_file_temp = pd.read_pickle(os.path.join(path, pkl_file))
        if pkl_file_temp.empty:
            raise ValueError(f"{pkl_file} æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
        trading_coins = pd.concat([trading_coins, pkl_file_temp], ignore_index=True)

    # è°ƒæ•´å®žç›˜é€‰å¸æ•°æ®çš„æ—¶é—´
    trading_coins['candle_begin_time'] = trading_coins['candle_begin_time'].map(
        lambda x: x.strftime('%Y-%m-%d %H:00:00'))
    trading_coins['candle_begin_time'] = pd.to_datetime(trading_coins['candle_begin_time'])

    # è¿‡æ»¤æ—¶é—´èŒƒå›´
    trading_coins = trading_coins[
        (trading_coins['candle_begin_time'] >= start_time) &
        (trading_coins['candle_begin_time'] <= end_time)
        ]
    if trading_coins.empty:
        raise ValueError("å®žç›˜é€‰å¸æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ 'start_time' å’Œ 'end_time' çš„è®¾ç½®")

    # æŒ‰æ—¶é—´åˆ†ç»„å¹¶ç”Ÿæˆé€‰å¸é›†åˆ
    backtest_coins['symbol_type'] = backtest_coins['is_spot'].map({1: 'spot', 0: 'swap'})
    backtest_coins['æ–¹å‘'] = backtest_coins['æ–¹å‘'].astype(int)
    backtest_coins['coins_name'] = (backtest_coins['symbol'] + '(' + backtest_coins['symbol_type'] + ','
                                    + backtest_coins['æ–¹å‘'].astype(str) + ')')

    trading_coins['symbol_type'] = trading_coins['symbol_type'].astype(str)
    trading_coins['coins_name'] = trading_coins['symbol'] + '(' + trading_coins['symbol_type'] + ',' + trading_coins[
        'æ–¹å‘'].astype(str) + ')'

    backtest_coins = backtest_coins.groupby('candle_begin_time').apply(lambda x: set(x['coins_name']))
    backtest_coins = backtest_coins.to_frame().reset_index().rename(columns={0: f'å›žæµ‹-{backtest_name}'})

    trading_coins = trading_coins.groupby('candle_begin_time').apply(lambda x: set(x['coins_name']))
    trading_coins = trading_coins.to_frame().reset_index().rename(columns={0: f'å®žç›˜-{backtest_name}'})

    # åˆå¹¶å›žæµ‹å’Œå®žç›˜é€‰å¸æ•°æ®
    merged = pd.merge(backtest_coins, trading_coins, on='candle_begin_time', how='inner')
    if merged.empty:
        raise ValueError("å›žæµ‹å’Œå®žç›˜é€‰å¸æ—¶é—´æ— æ³•å¯¹é½ï¼Œè¯·æ£€æŸ¥æ•°æ®")

    # è®¡ç®—æŒ‡æ ‡
    merged['å…±æœ‰é€‰å¸'] = merged.apply(lambda x: x[f'å›žæµ‹-{backtest_name}'] & x[f'å®žç›˜-{backtest_name}'], axis=1)
    # è®¡ç®—å›žæµ‹é€‰å¸ç‹¬æœ‰ï¼ˆåœ¨å›žæµ‹ä¸­ä½†ä¸åœ¨äº¤é›†ä¸­ï¼‰
    merged['å›žæµ‹ç‹¬æœ‰é€‰å¸'] = merged.apply(lambda x: x[f'å›žæµ‹-{backtest_name}'] - x['å…±æœ‰é€‰å¸'], axis=1)
    # è®¡ç®—å®žç›˜é€‰å¸ç‹¬æœ‰ï¼ˆåœ¨å®žç›˜ä¸­ä½†ä¸åœ¨äº¤é›†ä¸­ï¼‰
    merged['å®žç›˜ç‹¬æœ‰é€‰å¸'] = merged.apply(lambda x: x[f'å®žç›˜-{backtest_name}'] - x['å…±æœ‰é€‰å¸'], axis=1)
    merged[f'å›žæµ‹-{backtest_name}é€‰å¸æ•°é‡'] = merged[f'å›žæµ‹-{backtest_name}'].str.len()
    merged[f'å®žç›˜-{backtest_name}é€‰å¸æ•°é‡'] = merged[f'å®žç›˜-{backtest_name}'].str.len()
    merged['é‡å¤é€‰å¸æ•°é‡'] = merged['å…±æœ‰é€‰å¸'].str.len()
    merged[f'ç›¸ä¼¼åº¦_åŸºäºŽå›žæµ‹-{backtest_name}'] = merged['å…±æœ‰é€‰å¸'].str.len() / merged[f'å›žæµ‹-{backtest_name}é€‰å¸æ•°é‡']
    merged[f'ç›¸ä¼¼åº¦_åŸºäºŽå®žç›˜-{backtest_name}'] = merged['å…±æœ‰é€‰å¸'].str.len() / merged[f'å®žç›˜-{backtest_name}é€‰å¸æ•°é‡']
    merged['ç›¸ä¼¼åº¦'] = (merged[f'ç›¸ä¼¼åº¦_åŸºäºŽå›žæµ‹-{backtest_name}'] + merged[f'ç›¸ä¼¼åº¦_åŸºäºŽå®žç›˜-{backtest_name}']) / 2

    return merged


def process_backtest_trading_factors(root_path, factors_name_list, backtest_name, coin):
    # è¯»å–å›žæµ‹å› å­å€¼ä¿¡æ¯
    backtest_kline = pd.read_pickle(os.path.join(root_path, 'data/cache/all_factors_kline.pkl'))

    for factor_name in factors_name_list:
        path = os.path.join(root_path, 'data/cache', f'factor_{factor_name}.pkl')
        factor = pd.read_pickle(path)
        if factor.empty:
            raise ValueError(f"{factor_name} å›žæµ‹å› å­æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
        backtest_kline[factor_name] = factor

    if backtest_kline.empty:
        raise ValueError("å›žæµ‹å› å­å€¼æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")

    # è¯»å–å®žç›˜å› å­å€¼ä¿¡æ¯
    trading_kline = pd.read_pickle(
        os.path.join(root_path, f'data/å›žæµ‹ç»“æžœ/{backtest_name}/å®žç›˜ç»“æžœ/runtime/all_factors_kline.pkl'))
    for factor_name in factors_name_list:
        path = os.path.join(root_path, f'data/å›žæµ‹ç»“æžœ/{backtest_name}/å®žç›˜ç»“æžœ/runtime/all_factors_{factor_name}.pkl')
        factor = pd.read_pickle(path)
        if factor.empty:
            raise ValueError(f"{factor_name} å®žç›˜å› å­æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
        trading_kline[factor_name] = factor

    if trading_kline.empty:
        raise ValueError("å›žæµ‹å› å­å€¼æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")

    # ç­›é€‰åŒå¸æ•°æ®
    # ç›®çš„æ˜¯å’Œå®žç›˜symbolå¯¹é½ï¼Œå®žç›˜çš„symbolæ²¡æœ‰è¿žå­—ç¬¦ï¼Œæ¯”å¦‚å›žæµ‹symbol 'BTC-USDT'ï¼Œå®žç›˜å¯¹åº”çš„symbolä¸º 'BTCUSDT'
    backtest_kline['symbol'] = backtest_kline['symbol'].apply(lambda x: x.replace('-', ''))
    single_coin_backtest_kline = backtest_kline[backtest_kline['symbol'] == coin]
    single_coin_trading_kline = trading_kline[trading_kline['symbol'] == coin]

    # æ£€æŸ¥å¸ç§
    if single_coin_backtest_kline.empty:
        print(f'{coin} ä¸åœ¨æœ¬å‘¨æœŸå›žæµ‹é€‰å¸ç»“æžœä¸­ï¼Œæ£€æŸ¥å¸åæ˜¯å¦è¾“å…¥æ­£ç¡®æˆ–è€…æ£€æŸ¥æ•°æ®ï¼Œè¯·é‡æ–°è¾“å…¥')
        return False
    if single_coin_trading_kline.empty:
        print(f'{coin} ä¸åœ¨æœ¬å‘¨æœŸå®žç›˜é€‰å¸ç»“æžœä¸­ï¼Œæ£€æŸ¥å¸åæ˜¯å¦è¾“å…¥æ­£ç¡®æˆ–è€…æ£€æŸ¥æ•°æ®ï¼Œè¯·é‡æ–°è¾“å…¥')
        return False

    # è°ƒæ•´å®žç›˜é€‰å¸æ—¶é—´
    single_coin_trading_kline['candle_begin_time'] = single_coin_trading_kline['candle_begin_time'].map(
        lambda x: x.strftime('%Y-%m-%d %H:00:00'))
    single_coin_trading_kline['candle_begin_time'] = pd.to_datetime(single_coin_trading_kline['candle_begin_time'])

    if set(single_coin_backtest_kline['candle_begin_time']).isdisjoint(
            set(single_coin_trading_kline['candle_begin_time'])):
        raise ValueError("å®žç›˜å›žæµ‹æ—¶é—´æ— äº¤é›†ï¼Œè¯·æ£€æŸ¥æ•°æ®")

    single_coin_trading_kline['is_spot'] = single_coin_trading_kline['symbol_type'].map({'spot': 1, 'swap': 0})
    single_coin_backtest_kline['type'] = single_coin_backtest_kline['is_spot'].map({1: 'çŽ°è´§', 0: 'åˆçº¦'})
    single_coin_trading_kline['type'] = single_coin_trading_kline['is_spot'].map({1: 'çŽ°è´§', 0: 'åˆçº¦'})

    # èŽ·å–å›žæµ‹å’Œå®žç›˜æ•°æ®çš„å¸ç§ç±»åž‹é›†åˆ
    backtest_coin_type = set(single_coin_backtest_kline['type'])
    trading_coin_type = set(single_coin_trading_kline['type'])
    all_type = backtest_coin_type & trading_coin_type  # äº¤é›†

    if backtest_coin_type != trading_coin_type:
        error_msg = f"""
        å›žæµ‹ä¸Žå®žç›˜æ•°æ®ä¸ä¸€è‡´ï¼š
        - å›žæµ‹æ•°æ®ä¸­çš„ {coin} ç±»åž‹: {backtest_coin_type}
        - å®žç›˜æ•°æ®ä¸­çš„ {coin} ç±»åž‹: {trading_coin_type}
        éœ€è¦æ£€æŸ¥æ•°æ®
        """
        raise ValueError(error_msg.strip())

    # æƒ…å†µ1ï¼šåŒæ–¹éƒ½æœ‰çŽ°è´§ç±»åž‹
    if 'çŽ°è´§' in all_type:
        # è¿‡æ»¤çŽ°è´§æ•°æ®ï¼ˆå‡è®¾ is_spot=1 è¡¨ç¤ºçŽ°è´§ï¼‰
        single_coin_backtest_kline = single_coin_backtest_kline[single_coin_backtest_kline['is_spot'] == 1]
        single_coin_trading_kline = single_coin_trading_kline[single_coin_trading_kline['is_spot'] == 1]

    # æƒ…å†µ3ï¼šåŒæ–¹éƒ½æ²¡æœ‰çŽ°è´§ï¼Œä½†å­˜åœ¨åˆçº¦ç±»åž‹
    elif 'åˆçº¦' in all_type and 'çŽ°è´§' not in backtest_coin_type | trading_coin_type:
        # è¿‡æ»¤åˆçº¦æ•°æ®
        single_coin_backtest_kline = single_coin_backtest_kline[
            (single_coin_backtest_kline['is_spot'] == 0) & (single_coin_backtest_kline['symbol_swap'] != '')]
        single_coin_trading_kline = single_coin_trading_kline[single_coin_trading_kline['is_spot'] == 0]

    # æ•´ç†æ•°æ®
    col_rename = ['close'] + factors_name_list
    single_coin_backtest_kline = single_coin_backtest_kline[['candle_begin_time', 'close'] + factors_name_list]
    single_coin_backtest_kline = single_coin_backtest_kline.rename(
        columns={x: f"å›žæµ‹_{x}(å³è½´)" if x != 'close' else f"å›žæµ‹_{x}(å·¦è½´)" for x in col_rename}
    )

    single_coin_trading_kline = single_coin_trading_kline[['candle_begin_time', 'close'] + factors_name_list]
    single_coin_trading_kline = single_coin_trading_kline.rename(
        columns={x: f"å®žç›˜_{x}(å³è½´)" if x != 'close' else f"å®žç›˜_{x}(å·¦è½´)" for x in col_rename}
    )

    # åˆå¹¶å›žæµ‹å’Œå®žç›˜å› å­å€¼
    merged_factors = pd.merge(single_coin_backtest_kline, single_coin_trading_kline, how='inner',
                              on='candle_begin_time')
    merged_factors.set_index('candle_begin_time', inplace=True)

    return merged_factors
